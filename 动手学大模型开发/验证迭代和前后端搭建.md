## 验证迭代

以调用和发挥大模型为核心的大模型开发流程，相较传统的AI开发更加注重验证迭代。

在使用语言模型（LLM）构建应用程序时，可以通过在少数样本上调整Prompt，快速得到反馈结果，并在测试集中添加难以处理的例子，逐步扩大开发集。

到那时在开发过程中可能遇到的挑战，如一些例子无法通过Prompt或算法解决。

但我们可以寻找Bad Case和对其进行针对性优化的思路。

## 解决BAD CASE

提升回答质量的方法有这些

- 针对性地修改 Prompt 模板，加入要求其回答具体，并去掉“谢谢你的提问”的部分：

从 “什么是南瓜书” 变成

```
"""使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答
案。你应该使答案尽可能详细具体，但不要偏题。如果答案比较长，请酌情进行分段，以提高答案的阅读体验。
{context}
问题: {question}
有用的回答:"""
```
当然还可以继续改进，比如减少使用首先、其次等词。

修改后：
```
"""使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答
案。你应该使答案尽可能详细具体，但不要偏题。如果答案比较长，请酌情进行分段，以提高答案的阅读体验。
如果答案有几点，你应该分点标号回答，让答案清晰具体
{context}
问题: {question}
有用的回答:"""
```

- 标明知识来源，提高可信度

很简单，要求AI生成时带上 **“请你附上回答的来源原文”** ，但是会以回答速度作为代价。

```
"""使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答
案。你应该使答案尽可能详细具体，但不要偏题。如果答案比较长，请酌情进行分段，以提高答案的阅读体验。
如果答案有几点，你应该分点标号回答，让答案清晰具体。
请你附上回答的来源原文，以保证回答的正确性。
{context}
问题: {question}
有用的回答:"""
```

- 构造思维链

这种做法让AI回答问题从一步变成两步，第一步**生成**，第二步**反思**。

修改后
```
"""使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答
案。你应该使答案尽可能详细具体，但不要偏题。如果答案比较长，请酌情进行分段，以提高答案的阅读体验。
如果答案有几点，你应该分点标号回答，让答案清晰具体。
请你附上回答的来源原文，以保证回答的正确性。
{context}
问题: {question}
有用的回答:"""
```

- 增加指令解析

将格式要求和问题内容拆开来，也是分多次完成。

## 大模型评估方法

- 人工评估
- 简单自动评估
- 使用大模型进行评估
- 混合评估