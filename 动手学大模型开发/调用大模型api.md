# 调用大模型api

### Prompt

为下游任务设计的一种任务输入模板，一种任务对应一种Prompt。

在大模型时代，输入为一个 Prompt，输出返回结果为 Completion。

例如在这个用例里，我提问 Prompt：

vulkan在GPU渲染任务中相比于同类有什么优势

AI回答的就是 Completion：


Vulkan是一种跨平台的图形API（应用程序接口），旨在提供高性能的图形和计算功能。相比于一些其他图形API，如OpenGL，Vulkan在GPU渲染任务中有一些明显的优势：

1. **更低的驱动开销：** Vulkan被设计为更底层的API，使开发者能够更直接地控制GPU。这意味着在图形和计算任务中，Vulkan可以更有效地利用硬件资源，减少驱动程序开销，从而提高性能。

2. **更好的多线程支持：** Vulkan为开发者提供了更灵活的多线程支持，允许更好地利用多核处理器。这对于现代GPU和CPU架构来说尤为重要，因为它们通常具有多个核心。通过更好的多线程支持，Vulkan可以更有效地分配任务和提高性能。

3. **显式内存控制：** Vulkan允许开发者更直接地管理GPU上的内存。这意味着开发者可以更精确地控制内存分配和释放，从而减少内存管理的开销，提高性能。

4. **更好的命令缓冲控制：** Vulkan允许开发者更细粒度地控制命令缓冲，这有助于最小化CPU和GPU之间的通信开销。这使得在渲染任务中更容易实现高效的并行处理。

5. **更好的异步计算支持：** Vulkan支持异步计算，允许GPU同时执行多个任务，包括图形渲染和通用计算。这有助于提高整体性能，尤其是在需要进行大量计算的应用程序中。

总体而言，Vulkan的设计目标是提供更高的性能和更好的硬件资源利用率，使开发者能够更精细地控制图形和计算任务。然而，使用Vulkan也需要更多的编程工作，因为它相对底层，需要开发者自行处理许多与图形编程相关的细节。

以后使用Api都会是关于这个，一个输入对应一个输出。

### Temperature

一个 0~1 的数值，我觉得可以让AI自己来解释这个。

在机器学习中，特别是在语言模型（如GPT-3，LLM可能指的是Large Language Model）中，"temperature"通常是用来调整生成的样本的多样性的参数。

在这个上下文中，temperature的作用是控制模型生成输出的随机性。具体来说，较高的温度会增加输出的随机性，使生成的样本更加多样化，而较低的温度则会减少随机性，使生成的样本更加确定性。

- **高温（大于1）：** 生成的样本更加随机，多样性更大，可能包含一些不太常见或不太合理的选项。这对于探索性的生成任务可能是有用的，但对于一些需要确切和可靠输出的任务可能不太适用。

- **低温（小于1）：** 生成的样本更加确定性，更加集中在模型认为最可能的输出上。这对于一些需要一致性和可控性的任务可能更为合适。

在实际应用中，调整temperature可以根据任务的要求来进行微调。例如，在进行创意性文本生成时，可以使用较高的temperature以促使模型生成更多的创新内容；而在进行问题回答等需要确定性的任务时，可以使用较低的temperature以确保生成的答案更加可靠。

在**搭建教程**、**个人知识库**等任务中，我们通常会设置为0，避免错误内容的产生；

而对于**文本创作**、**营销文案**等任务中，就需要创意性，可以设置更高的值。

### 调用星火API

在本次大模型开发任务中，我需要使用的是**星大模型API**，以避免使用国外AI产品导致的合规风险。


todo: 尝试调用星火大模型，为以后开发做准备！