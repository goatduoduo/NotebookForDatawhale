# 概述

大语言模型从20世纪90年代开始研究，从统计学习方法到2003年首次深度学习方法，即**神经网络模型**，并从2018年左右引入了**Transformer架构的神经网络模型**，它终于能够深入理解语言规则和模式。

语言模型越大，能力越强，随之进入了大语言模型时代（LLM）。

大语言模型（英文：Large Language Model，缩写LLM），也称大型语言模型，是一种人工智能模型，旨在理解和生成人类语言。

参数量能够达到百亿甚至千亿的级别，例如1750亿的GPT-3和5400亿的PaLM，这些超大的模型在解决复杂任务时表现的更好。

这类模型在自然语言处理、检索、视觉领域都带来了巨大的影响，更重要的是关于通用AI的可能性。

## 能力

### 涌现能力（emergent abilities）

在小模型中不明显而在大模型中显著出现的能力，性能随着模型的规模增大迅速提升，量变引发质变。

涌现能力包括：

1. 上下文学习：他会记住我问的问题或者之前回答的问题，部分任务需要依赖上下文。例如编写文档修改部分内容的场景。
2. 指令遵循：使用指令描述来应对未知的任务。
3. 逐步推理：用思维链的策略利用中间推理步骤的提示机制来解决任务。

这样的能力使得其成为了解决复杂问题和面对多领域的工具。

### 作为基座模型支持多元应用的能力

将通用模型经过大模型二次开发转化为特定模型，大幅减少了开发周期和人力投入。因此可以成为一个非常强大的基座模型。

### 支持对话作为统一入口的能力

chatGPT本身作为一个可以用于聊天的机器人，就已经很惊艳了，它彻底改变了原先聊天机器人的游戏规则。

未来会出现更多的对话助手或者其特化版本。

## 特点

1. 巨大的规模
2. 预训练和微调
3. 上下文感知
4. 多语言支持
5. 多模态支持
6. 涌现能力
7. 多领域应用
8. 伦理和风险问题

## 常用大模型

### 闭源

- GPT
- ChatGPT
- GPT-4
- Calude
- PaLM
- 文心一言
- 星火

### 开源

- LLaMA
- GLM
- 通义千问
- Baichuan 系列

## LangChain

它是帮助开发者快速构建大语言模型应用程序或者工作流程的开源工具。

它提供了各种大语言模型应用提供的通用接口，简化开发流程。

核心部件包括：

- 模型输入/输出（Model I/O）：与语言模型交互的接口
- 数据连接（Data connection）：与特定应用程序的数据进行交互的接口
- 链（Chains）：将组件组合实现端到端应用。
- 记忆（Memory）：用于链的多次运行之间持久化应用程序状态；
- 代理（Agents）：扩展模型的推理能力。用于复杂的应用的调用序列；
- 回调（Callbacks）：扩展模型的推理能力。用于复杂的应用的调用序列；