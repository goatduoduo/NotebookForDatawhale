# softmax回归
该回归关注的是“分类”问题，例如
- 某个电子邮件是否属于垃圾邮件文件夹？
- 某个用户可能注册或不注册订阅服务？
- 某个图像描绘的是驴、狗、猫、还是鸡？
- 某人接下来最有可能看哪部电影？

分类用于描述两个有微妙差别的问题：

1. 我们只对样本的“硬性”类别感兴趣，即属于哪个类别
2. 我们希望得到“软性”类别，即得到属于每个类别的概率。 

回归估计一个连续值
分类预测一个离散类别

| 回归                   | 分类                       |
| ---------------------- | -------------------------- |
| 单连续数值输出         | 通常多个输出               |
| 自然区间 $R$           | 输出i是预测为第i类的置信度 |
| 跟真实信的又别作为损失 |

## 均方损失

- 对类别进行**一位有效**编码
- $y = [{y_1},{y_2} \ldots ,{y_n}]$
- \[ y_i =
  \begin{cases}
    1       & \quad \text{if } i = y\\
    0  & \quad \text{otherwise }
  \end{cases}
\]
- 使用均方损失训练
- 最大值最为预测 $\widehat y = {\arg _i}\max {o_i}$
- 需要更置信的识别正确类 $ o_y-o_i>=\Delta (y,i)$

## 校验比例

输出匹配概率（非负，和为1）
$$\widehat y = soft\max (o)$$
$$\widehat {{y_i}} = {{{e^{{o_i}}}} \over {\sum\nolimits_k {{e^{{o_k}}}} }}$$
概率$y$和$\widehat {{y}}$的区别作为损失

一般使用交叉熵来比对概率的区别

##交叉熵
- 交叉常用来衡量两个概率的区别$H(p,q) = \sum\limits_i {}  - {p_i}\log ({q_i})$
- 将它作为损失
- $$l(y,\widehat y) =  - \sum\limits_i {{y_i}\log \widehat y}  =  - \log \widehat y$$
- 其梯度是真实概率和预测概率的区别
- $${\partial _{{o_i}}}l(y,\widehat y) = soft\max {(o)_i} - {y_i}$$

我们关心正确类的预测值

## 总结
- Softmax 回归是一个多类分类模型
- 使用Sohtmax操作子得到每个类的预测置信度
- 使用交又来来衡量预测和标号的区别