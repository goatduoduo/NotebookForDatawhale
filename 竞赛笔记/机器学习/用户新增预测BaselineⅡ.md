### 模型比对

#### lightGBM 0.46923

![这是图片](/img/output1.png "gbm表格")

```
训练轨迹，用时 9min40s
[100]	cv_agg's binary_logloss: 0.308539 + 0.00131195	cv_agg's f1score: 0.591357 + 0.00271934
[200]	cv_agg's binary_logloss: 0.293358 + 0.000653323	cv_agg's f1score: 0.632815 + 0.00065806
[300]	cv_agg's binary_logloss: 0.283234 + 0.00104033	cv_agg's f1score: 0.656886 + 0.000474225
[400]	cv_agg's binary_logloss: 0.274837 + 0.00132123	cv_agg's f1score: 0.675262 + 0.000531944
[500]	cv_agg's binary_logloss: 0.268956 + 0.00115948	cv_agg's f1score: 0.687613 + 0.000710861
[600]	cv_agg's binary_logloss: 0.264601 + 0.00095846	cv_agg's f1score: 0.696162 + 0.0011005
[700]	cv_agg's binary_logloss: 0.260701 + 0.00101349	cv_agg's f1score: 0.704398 + 0.000836649
[800]	cv_agg's binary_logloss: 0.25688 + 0.00112378	cv_agg's f1score: 0.712409 + 0.00164459
[900]	cv_agg's binary_logloss: 0.253914 + 0.000953801	cv_agg's f1score: 0.718521 + 0.00114718
[1000]	cv_agg's binary_logloss: 0.251388 + 0.000646632	cv_agg's f1score: 0.724059 + 0.000623463
```

我猜测过拟合


#### RandomForestBag 0.5303

![这是图片](/img/output2.png "gbm表格")

![这是图片](/img/output3.png "gbm表格")
```
用时 19min23s
100%|██████████| 7/7 [18:27<00:00, 158.19s/it]
      score    i
5  0.756818  800
4  0.756788  700
3  0.756735  600
6  0.756678  900
1  0.756581  400
0  0.756517  300
2  0.756507  500
```

当训练集的F1比测试集的F1更大时，我认为这可能发生了过拟合。
以下是一些可能导致训练集上F1值较高的因素：

    过拟合：当模型过于复杂，并且在训练数据上过度调整以适应噪声时，会导致过拟合。过拟合的模型可以在训练数据上表现得非常好，但在未见过的测试数据上表现较差，因为它们捕捉了训练数据中的细微变化和噪声。

    数据不平衡：如果训练数据中的正负样本比例不平衡，模型可能倾向于预测占多数的类别，从而导致较高的精确率或召回率。这可能会导致在训练集上获得较高的F1值，但在测试集上表现不佳。

    特征泄漏：在数据预处理或特征工程过程中，如果模型接触到了测试集的信息，可能会导致特征泄漏。这会使模型在测试集上表现更好，因为它已经“看到过”测试数据。

分析下来，我认为“过拟合”确实发生了，并且很明显正例的比例要远远小于反例，是“不平衡”的。