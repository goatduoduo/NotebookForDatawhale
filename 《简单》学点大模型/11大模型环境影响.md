# 大模型对环境的影响

本章关于大语言模型对环境的影响，并预估训练特定语言模型所带来的排行两，并提高对监测和减轻对环境的影响的认知。

## 生命周期评估

AI和机器学习对环境的影响需要从系统方法来思考。

- 对环境的全面影响（排放、水足迹）
- IT设备的整个生命周期

从**生命周期评估**的角度来说：
- 生命周期评估（LCA）（ISO 14040和14044）为实现这一点提供了一个框架。
- 需要“从系统的角度”来避免“一个问题的解决方案会产生几个新的、经常被忽视的问题”。


从**环境影响**的角度来说：
- 温室气体排放
- 水足迹
  - 数据中心需要水用于冷却
  - 发电需要用水，处理水需要电力
- 对人类的危害
  - 生产芯片带来的有害物质
- 非生物资源枯竭
  - 化石燃料
  - 矿物资源

次生影响：
- 更高的效率带来更大的需求
- 环境变化
- 冻土融化加剧温室效应
- 芯片短缺

$$
\text{language model} \quad\Rightarrow\quad \text{compute} \quad\Rightarrow\quad \text{energy use} \quad\Rightarrow\quad \text{greenhouse gas emissions} \quad\Rightarrow\quad \text{environmental impact}
$$

其实就是这样的一个影响链条。

## 气候变化

关于人工智能和机器学习对环境造成的影响。

气温正在上升，所带来了自然灾害增加和海平面上升导致的负面影响。

导致这个的原因有：温室气体的大量排放，排放量自1970年来上升了90%，人类的活动加速带来了更多的排放。

碳排放量的计量单位为kg CO2 eq：
- 每种温室气体都具有**全球变暖潜力**
    - 取决于（i）吸收的热量和（ii）它在大气中停留的时间。
    - 对于二氧化碳，全球升温潜能值=1（定义为参考值）。
    - 对于甲烷，100年全球升温潜能值=25。
    - 对于一氧化二氮，全球升温潜能值在100年内为300（因为它存在的时间太长了——121年）。

## 能源使用和温室气体排放

数据中心使用的能源可以映射到排放量上。

它取决于电力的产生来源，有一个度量叫做**碳强度（Carbon intensity:）**：使用每千瓦时能源排放的碳量。

- 化石燃料最多
- 绿色能源会因为全生命周期也会间接产生排放（但更少）
- 在相同条件下，水电排放量比煤炭少30倍

## 预估训练模型的排放量

- [ML CO2 Impact Calculator](https://mlco2.github.io/impact/)（[Lacoste et al., 2019]("https://arxiv.org/pdf/1910.09700.pdf)）提供了一种基于硬件、使用的小时数、供应商和地区来估计排放量的简单方法。
- Strubell et al., 2018 一篇关于NLP社区对环境影响认识的论文。计算用电效率和平均排放量/千瓦时，就可以量化碳排放量了。
- Patterson et al., 2021 也是一篇论文，用一个公式概括了排放量和工作负载的关系。

$$
\text{emissions} = R_{\text{power} \to \text{emit}} (\text{energy-train} + \text{queries} \cdot \text{energy-inference})
$$

但不同模型之间差距过于巨大，尤其是小任务或者神经结构任务导致被高估。

## 总结

- 环境影响是一个巨大的话题。一切都是相互联系的，所以很难得出一个干净的定量指标。但要真正着眼于全局。
- 尽管如今大语言模型的还很少，但它正在快速增长。
- 大语言模型的通用性提供了节省成本的潜力（“一次性训练”并适用于许多不同的任务）。但它们的成本要高得多，需要可能需要重新训练。这里的权衡是什么？

- **缓解措施**：
    - 尝试在使用清洁能源的数据中心训练模型
    - 碳抵消的效果各不相同（森林种植活动产生单一种植）
    - 更高效的模型架构、训练程序、硬件（但要注意反弹效应）

- **在论文报告排放量**：
    - 可以提高认识（想象一下，如果每一篇论文都能报告排放量）
    - 调整激励（人们目前关注准确性，但碳排放也很重要！）
