# 分布式训练

深度学习的模型的特点是模型规模极大,例如GPT-3达到了1750亿。

这个概念相当于需要用1024张 A100，持续30天才能训练 GPT-3。

当然持续强化单点进行训练大模型始终是个不现实的事情（除非进行新一轮工业革命）。

所以人们会考虑用多点集群的方式进行分布式训练，从而提高算力。

## 常用并行策略

为了高效的分布式训练，除了需要多个设备同时运算，也涉及到数据传输。

### 数据并行

策略是将数据 $x$进行切分，而每个设备上的模型$w$是相同的。

但是在反向传播的过程中，由于数据不同，两台设备的梯度和损失不一致，因此需要进行AllReduce，确保两个模型保持一致。

当数据集大模型小的时候比较实用，因为通信代价也比较小。

常见的例子是ResNet50，比较适合采用数据并行。

### 模型并行

每个设备的数据是完整的，但模型切割到了不同的设备上，因此只有拼接模型才能得到一个完整的模型。

这样不需要多个设备之间进行AllReduce，但缺点是要求每个设备都有完整的数据，因此通信代价会变大。

常见的例子是BERT。

### 流水并行

流水并行将网络分为多个阶段，然后分发到不同的设备上，接力完成训练。

只要任务能够切割就可以进行流水化运算。

### 混合并行

多种策略混合使用，例如GPT-3

首先分为64个阶段，进行**流水并行**，其次每个阶段运行在6台 DGX-A100 主机上，进行**并行训练**，每个主机还有8张GPU显卡同时训练。

总结就是：并行策略的选择影响着训练效率，框架对并行训练的接口支持程度，决定了算法工程师的开发效率。