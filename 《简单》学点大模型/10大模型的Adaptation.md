使用语言模型通过仅给出提示，我们已经能够执行一些任务。但并不适用于所有的下游任务。

下游任务与语言模型的训练数据可能在格式上和主题上有所不同，或者知识会随时间更新。因此，语言模型需要“适配”。

Adaptability Development Adjustment  Progress Transformation Alteration Transition Improvement Optimization Next

A.D.A.P.T.A.T.I.O.N.

### 为什么需要Adaptation

GPT-3针对广泛的领域进行训练，而现实任务通常与原始任务之间存在差异。

- 格式不同
  - 自然语言推理：下游任务如NLI涉及两个句子的比较以产生单一的二进制输出。这种任务与常规的MASK训练方式很不一样。
  - BERT训练与MASK标记：BERT使用MASK标记进行训练，但很多任务并不是这么训练的，所以需要进行调整。
- 主题转变
  - 特定领域的需求：比如说医疗文档分析或者法律文档分析，这种任务根本不是通用语言模型训练所能覆盖得到的。
  - 广泛主题的灵活性：语言模型可能会处理新领域或者冷门领域，超出原先的训练范围。
- 时间转变
  - 新知识的需求：一些任务会使用超过该模型训练时间的知识，因此模型无法覆盖到。
  - 非公开信息需求：一些任务涉及到专业领域，往往并不是公开的。

### 通用的Adaptation配置

使用预训练语言模型的参数来适配下游任务的一般配置，以下是组成部分：

1. **预训练语言模型**：
在适配开始时，我们已有一个预训练的语言模型，用参数$θLM$表示。他是一个通用的模型，不针对特定任务训练。

2. **下游任务数据集**：
一个来自下游任务 $P_{task}$ 的样本数据，来自特定领域。每个样本由输入x和目标输出y组成，如：$\left(x^{(1)}, y^{(1)}\right), \ldots,\left(x^{(n)}, y^{(n)}\right)$。

3. **适配参数**：
为了完成适配，需要寻找一组参数$\gamma$，用于调整模型使得其在特定任务表现更好。

4. **任务损失函数**：
仍然需要定义损失函数$\ell_{\text {task }}$来衡量模型在下游任务上的表现。可以选择交叉熵。

5. **优化问题**：
寻找一组适配参数$\gamma_{\text {adapt }}$，使得任务损失在整个下游数据集上最小化。数学上，这可以通过以下优化问题表示：
$$
\gamma_{\text {adapt }}=\operatorname{argmin}_{\gamma \in \Gamma} \frac{1}{n} \sum_{i=1}^n \ell_{\text {task }}\left(\gamma, \theta_{\mathrm{LM}}, x_i, y_i\right) .
$$

这样就可以通过适配参数来适配模型，这样就可以适配到特定的下游任务上了。

## 主流的Adaptation方法

### Probing
主要适用于仅编码器模型（如BERT），对于Adaptation来说，我们从语言模型（LM）的最后一层表示中训练一个Probing（或预测头）到输出。

Probing方法是通过线性的或浅前馈网络来学习预训练模型的输出，并获得分析和理解模型内容表示的能力，从而在下游任务中取得不错的表现。

### Fine-tuning
Fine-tuning（微调）使用语言模型参数$θLM$作为优化的初始化。其中，优化后的参数家族$\Gamma$包括了所有的语言模型参数和任务特定的预测头参数。与此同时，预训练的优化器状态被丢弃。

### Lightweight Fine-tuning

轻量级微调是一种特殊的微调技术，旨在结合全面微调的表现力和更节省资源的优点。轻量级微调试图在不需要为每个任务存储完整语言模型的同时，保持与全面微调相同的表现力。换句话说，它希望在减小模型存储需求和计算负担的同时，仍然实现出色的性能。

是一种兼顾性能和效果的策略。

### Prompt Tuning

提示调整是一种特殊的微调技术，主要用于文本分类任务。Prompt Tuning的灵感来源于推理为基础的自适应提示设计/工程。与传统的微调方法不同，提示调整专注于优化输入提示，而不是改变模型的内部参数。

## 总结

我们需要将大语言模型适配到不同的下游任务中，而这些任务通常与训练建模有很大的不同。

1. **探测法（Probing）**：探测法在冻结的语言模型之上训练一个特定任务的预测头，将语言模型视为良好的表示提取器。冻结语言模型倾向于限制该方法的表现能力。
2. **微调（Fine-tuning）**：微调将大型语言模型参数视为下游任务的进一步训练的初始化，这比探测更具表现力，但也更昂贵，因为我们必须为每个下游任务保存整个模型。
3. **轻量级微调（Lightweight fine-tuning）**：轻量级微调在微调和探测之间取得了平衡，只优化少量参数（模型的<1%），但它优化了模型的高杠杆部分，因此仍然非常具有表现力。
通过上述方法，可以更灵活地应对各种不同的下游任务，既实现了对特定任务的精确适配，又在一定程度上控制了计算和存储的成本，从而在实际应用中取得更好的性能和效率。