<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>
# 模型评估和选择

本章节关于评估模型的优劣和选择最适合自己业务的模型。

### 经验误差与过拟合

错误率：分类错误的样本占样本总数的比例。$E=\frac{a}{m}$，其中m是样本总数，a为分类错误的样本总数。

精度：1-错误率，通常是百分数。

误差：学习器实际预测输出和样本真实输出之间的差异。
- 在训练集上的误差叫做“训练误差”或“经验误差”
- 在新样本上的误差叫做“泛化误差”

> 通常在学习任务中，可以得到训练误差很低的学习器，但是这并不是想要的学习器，因为往往在新样本下表现并不好，哪怕在训练集上能达到100%。也就是发生了“过拟合”。

过拟合：模型学习能力相对于数据过于强大，这通常并不是好事。

欠拟合：模型学习能力不足，无法学到一般规律。

> 有人总是说xx学习能力不足，但并不总是因为缺少学习，过多学习也会带来相同的结果，导致过犹不及。过拟合就是这样的一种现象，反复做训练题确实固然能让学生学会题目，但是可能他不会去记住做法，而是记住数据和答案，导致遇到新的相同解法的题目导致不会做。
> 
> 某种程度证明过犹不及，合适才是最好的。

### 评估方法

为了评估学习器的泛化误差，我们必须让训练样本和测试样本分开。在一个包含m个样例的数据集$D=\{(x_{1},y_{1}),(x_{2},y_{2}),...,(x_{m},y_{m})\}$ 中进行处理获取训练集$S$和测试集$T$。

留出法：直接将样本$D$划分为两个互斥的集合，一般拿$66\%-80\%$的样本用于训练，其余用于测试。

交叉验证法：将数据集划分为k个大小相似的互斥子集。将其中一个作为测试集，其余作为训练集训练，训练完成之后再把另一个作为测试集，然后以相同的方式继续训练，重复k次。

例如我把一个样本分为了三个样本集$D_{1}$，$D_{2}$，$D_{3}$，我们可以做如下操作：
- 训练集D1 D2，测试集D3
- 训练集D1 D3，测试集D2
- 训练集D2 D3，测试集D1

本质上还是多次留出法

自助法：给定m个样本的数据集D，对它进行采样产生数据集D'：每次随机从D中挑选一个样本，将其拷贝放入D'，但是D不会因此少一个样本，将这些步骤重复n次。

所以必定有重复出现的元素，也会有元素不会被抽到，一次没有抽中的会成为测试集，概率为 $\frac{1}{e}$

该方法可以产生不同的训练集，适用于较小难以有效划分的训练集。

### 性能度量

性能度量是模型泛化能力的评价标准。

一般常用的批判标准是：错误率、精度、查准率、查全率、F1、ROC和AUC

错误率：分类错误的概率，一般用于分类任务，下同。

精度：分类正确的概率

查准率（precision）和查全率（recall）更加适合分类问题性能的衡量。

对于真实结果和学习器预测结果组合划分可分为四类：

 |  | 预测正例 | 预测反例 |
 | -----------| ----------- | ----------- |
 | 实际正例 | TP | FN |
 | 实际反例 | FP | TN |

 查准率$P$:学习器预测为正例的样例中有多少是真正例$TP$

 $P=\frac{TP}{TP+FP}$

 查全率$R$:所有正例有多少被学习器预测到为正例

 $R=\frac{TP}{TP+FN}$

 以查全率为纵轴、查全率为横轴作图，可得到“P-R曲线”，用于评判模型算法。
![这是图片](/img/prcurve.png "P-R")

F1度量是查准率（Precision）和查全率（Recall）的调和平均数。
F1度量的计算公式如下：

$F1=\frac{2×P×R}{P+R​}$

F1比精确度更能衡量机器学习算法性能。

加权调和平均：在通常场景下，表现的是一种对查全率或者查准率的偏好，一般偏好用$\beta$表示

- $\beta>1$ 查全率更重要
- $\beta<1$ 查准率更重要
- $\beta=1$ 标准F1
- $\beta<0$ 它只存在于反世界

加权后的F1公式变为

$F_{\beta } =\frac{(1+\beta ^{2} )×P×R}{\beta ^{2}×P+R​}$

n个二分类的混淆矩阵也可以求P和R，在各个矩阵上求P和R，然后进行算术平均，就得到了macro-P和macro-R，然后计算各个值的方法都是一样的，只需要带上macro的前缀就可以。