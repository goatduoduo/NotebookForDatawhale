# 绪论
> 在机器学习出现之前，我们通过经验从西瓜的各个特征判断是否是“好瓜”。

- **机器学习**是利用计算来获取经验来改善系统自身性能。
- **学习算法**是机器学习的主要内容是关于从数据中产生模型的算法。
- **模型**指从数据中学得的结果，是算法产出的最终结果，例如线性回归中的一元一次函数。

> 机器学习的原理似乎也适用于人类本身的学习原理？


## 术语

样本（示例）：对一个事件或者对象的描述。计算机擅长处理数学问题，因此需要从实际样本抽象成数学形式。用特征描述，然后用**向量**的形式表达，例如某只西瓜可以表示为$x=(青绿; 蜷缩; 清脆)$.

样本维数：简单说一个样本包含几个特征就是几维，上面的样本就是3维的，$d=3$。

样本集（数据集）：令 $D = \{x_{1} , x_{2}, ..., x_{m}\}$，包含m个样本的数据集。一个样本可能有多个特征。

学习（训练）：从数据中获得模型的过程被称为“学习”或“训练”，训练用的数据叫做“训练数据”，每个样本被称为“训练样本”，训练样本组成的集合叫做“训练集”。

模型：“模型”也会称为“学习器”，在深度学习中会叫的比较多。

标记：一个样例的结果，例如在学习西瓜的好坏时，“好瓜”和“坏瓜”便是样本的标记。一般用$y_{i}$表示第i个样例的标记，$Y$表示所有标记的集合，也就是“标记空间”或者“输出空间”。

根据是否用到标记信息，机器学习可分为两类：
- 监督学习：使用到标记信息y
- 无监督学习：不使用标记信息y

> 因此机器学习习得模型可以看作从**输入空间X到输出空间Y**的映射，然后通过机器学习算法来寻求这个映射的模型。

分类：一种关于“离散值预测”的学习任务，例如分类正例和反例。

回归：一种关于“连续值预测”的学习任务，例如预测西瓜成熟度0.923。

测试：使用学习后的模型进行预测，被预测的样本就是测试样本。

泛化：对未知事物的判断能力，学得的模型适用于新样本的能力，就是泛化能力。

> 数据决定模型效果上限，通常数据量越大模型效果越好（但也有更大过拟合风险）。
> 
> 算法让模型逼近上限，数据准备充分时，使用不同算法学到的模型有高低之分（通常评判依据是泛化能力），效果越好越逼近上限，也就是真相。
>

## 假设空间

学习过程可以认为是在所有“假设”组成的空间中进行搜索的过程，对于西瓜分类问题，可以用“合取式”表示。
例如西瓜问题的假设空间为：

- (色泽=\* 根蒂=\*;敲声=\*)
- (色泽=青绿 根蒂=\*;敲声=\*)
- (色泽=乌黑 根蒂=\*;敲声=\*)
- (色泽=青绿 根蒂=蜷缩;敲声=\*)
- (色泽=青绿 根蒂=硬挺;敲声=\*)
- (色泽=青绿 根蒂=蜷缩;敲声=浊响)
- ......

房价预测问题的假设空间为：
- $y=3x-2$
- $y=x^2$

因此所有能拟合训练集的模型构成的集合，都称为“版本空间”。

## 归纳偏好

不同的机器学习算法有不同的偏好，就是“归纳偏好”，表示对某种假设的偏好。

可看作算法在一个很大的假设空间内对假设进行选择的价值观。

奥姆斯剃刀原则：如果多个假设和观察一致，选择最简单的那个。